\documentclass[11pt]{beamer}

\usepackage{amsmath}%
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{graphicx}
%\usepackage[brazil]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{scalefnt}
\usepackage{setspace}
\usepackage{color}
\usepackage{ragged2e}
\usepackage{hhline}
\usepackage{multirow}
\usepackage[
type={CC},
modifier={by-sa},
version={4.0},
lang={Brazilian},
imagewidth = {1cm},
]{doclicense}

\usepackage{pgf}
%\usepackage{algpseudocode,algorithm}
\usepackage[lined]{algorithm2e}
%\usepackage{algorithm2e}

%\definecolor{green}{RGB}{0,125,0}
%\definecolor{green}{RGB}{51,102,0}
%\definecolor{blue}{RGB}{0,0,125}
%\usetheme{Frankfurt}
%\usetheme{Warsaw}
%\usecolortheme{seagull}
%\usetheme{Madrid}
\usetheme{CambridgeUS}
%\usecolortheme[named=green]{structure}
%\setbeamercolor{section in head/foot}{bg=blue}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{headline}{}

\title[]{Introdução a Redes Neurais Artificiais}
\author[]{%
	%\color{blue}
	Prof. Jefferson T. Oliva\\~\\
	%\texttt{@utfpr.edu.br}
}
\institute{Reconhecimento de Padrões (RC18EE)\\Engenharia de Computação\\Programa de Pós-Graduação em Engenharia Elétrica e de Computação (PPGEEC)\\Universidade Tecnológica Federal do Paraná (UTFPR)\\Campus Pato Branco}
\date[]{
	
}


\addtobeamertemplate{navigation symbols}{}{%
	\usebeamerfont{footline}%
	\usebeamercolor[fg]{footline}%
	\hspace{1em}%
	\insertframenumber
}


\begin{document}
	
	\begin{frame}[t]
		\titlepage
		%\begin{center}
		\begin{figure}
			\includegraphics[width=2.5cm]{dainf.png}
			\hspace{5cm}
			\includegraphics[width=3cm]{utfpr_logo.jpg}
		\end{figure}
		%\end{center}
	\end{frame}



\begin{frame}[t]
	\frametitle{Sumário}
	\begin{itemize}
		\item Redes Neurais Artificiais\\~\\
		
		\item Perceptron\\~\\
		
		\item Perceptron Multicamadas
	\end{itemize}
\end{frame}



\begin{frame}[t]
	\frametitle{Introdução}
	\begin{itemize}
		\item Redes neurais artificiais são modelos matemáticos inspirados na estrutura neural biológica
		
		\begin{itemize}
			\item Compostas por unidades de processamento simples, denominados neurônios artificiais\\~\\
			
			\item Os neurônios artificiais são interconectados e comumente organizados em camadas\\~\\
			
			
		\end{itemize}
	\end{itemize}

	\begin{figure}
		\centering
		\includegraphics[width=70mm]{neuro}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Introdução}
	\begin{itemize}
		\item Breve histórico
		
		\begin{itemize}
			\item McCulloch \& Pitts (1943): modelo matemático do neurônio\\~\\
			
			\item Hebb (1949): formulação explícita de uma regra fisiológica para modificação sináptica (``Postulado de Aprendizado de Hebb'')\\~\\
			
			\item Rosenblatt (1958): rede Perceptron\\~\\
			
			\item Minsky \& Papert (1969): demonstraram limitações dos Perceptrons de uma única camada\\~\\ %Sugeriram que não haveria motivo pra acreditar que Perceptrons de múltiplas camadas poderiam superar as limitações. Diminuíram significativamente os trabalhos sobre RNAs
			
			
			\item Hopfield (1982): ``física com redes neurais''\\~\\
			
			\item Kohonen (1982): mapas auto-organizáveis\\~\\
			
			\item Rumelhart, Hinton \& Williams (1986): Backpropagation %Retomada definitiva do grande interesse em Redes neurais; Perceptrons de múltiplas camadas podem aprender problemas não linearmente separáveis
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Sumário}
	\begin{block}{}
		\begin{center}\bf Redes Neurais Artificiais\end{center}
	\end{block}
\end{frame}


%\begin{frame}[t]
%	\frametitle{Redes Neurais Artificiais}
%	\begin{itemize}
%		\item Redes Neurais Artificiais (RNAs) fornecem um método geral e prático para a aprendizagem de funções de valor real e de valor discreto a partir de exemplos\\~\\
%		
%		\item A aprendizagem de redes neurais é robusta a erros e ruídos nos dados de treinamento\\~\\
%		
%		\item Aplicações práticas
%		
%		\begin{itemize} \footnotesize
%			\item Reconhecimento da fala\\~\\
%			
%			\item Reconhecimento de faces\\~\\
%			
%			\item Reconhecimento de caracteres manuscritos\\~\\
%			
%			\item Bioinformática e medicina\\~\\
%			
%			\item Predição financeira\\~\\
%			
%			\item ...
%		\end{itemize}
%	\end{itemize}
%\end{frame}



%		\item Motivação biológica (seres humanos)
%		
%		\begin{itemize}
	%			\item Tempo de chaveamento do neurônios: 0,001s\\~\\
	%			
	%			\item Número de neurônios: 10.000.000.000\\~\\
	%			
	%			\item Conexões por neurônio: 10.000 a 100.000\\~\\
	%			
	%			\item Tempo para o reconhecimento de uma cena: 0,1s\\~\\
	%			
	%			\item Muita computação paralela\\~\\
	%		\end{itemize}

\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Redes Neurais Artificiais (RNAs) fornecem um método geral e prático para a aprendizagem de funções de valor real e de valor discreto a partir de exemplos\\~\\
		
		%Redes neurais podem aprender tanto funções de valor real (regressão, como prever preços ou sinais contínuos) quanto funções de valor discreto (classificação, como identificar dígitos ou categorizar imagens).
		
		%Isso mostra a flexibilidade das RNAs para resolver diversos tipos de problemas
		
		\item A aprendizagem de redes neurais pode ser robusta a erros e ruídos nos dados de treinamento\\~\\ %Diferente de alguns métodos mais sensíveis, redes neurais conseguem generalizar mesmo quando os dados de treinamento têm falhas, medições incorretas ou ruídos. Essa característica é essencial em aplicações reais, onde os dados raramente são perfeitos.
		
		\item RNA é um modelo inspirado na aprendizagem de sistemas biológicos de redes complexas de neurônios interconectados\\~\\ %O modelo de RNA se baseia, de forma abstrata, no funcionamento do cérebro humano, formado por bilhões de neurônios interconectados. %Cada neurônio artificial recebe sinais de entrada, processa-os e gera uma saída ? imitando a comunicação entre neurônios biológicos.
		
		\item Trabalhos em RNAs começaram com o desejo de entender o cérebro\\~\\
		
		%O estudo das redes neurais começou com o objetivo de compreender o cérebro e reproduzir seu mecanismo de aprendizagem.
		
		%Pesquisadores como McCulloch e Pitts (1943) e, posteriormente, o Perceptron de Rosenblatt (1958), foram marcos iniciais.
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Atualmente, o objetivo principal (ainda) de uma RNA é reproduzir seu funcionamento em diversas tarefas: paradigma conexionista
	\end{itemize}
	
	%O paradigma conexionista busca modelar o comportamento inteligente a partir da interconexão de unidades simples, inspiradas nas neuronas biológicas.
	
	%A ideia central é que a aprendizagem emerge da interação dessas unidades, sem a necessidade de regras explícitas ou simbólicas.
	
	\begin{figure}
		\centering
		\includegraphics[width=70mm]{ampi12}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Neurônio artificial
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=90mm]{ampi13}
	\end{figure}
\end{frame}


%\begin{frame}[t]
%	\frametitle{Redes Neurais Artificiais}
%	\begin{itemize}
%		\item RNAs são modelos de computação com propriedades particulares:
%		
%		\begin{itemize}
%			\item \textbf{Aprender}
%			
%			\item Adaptar
%			
%			\item Generalizar
%			
%			\item Eventualmente organizar
%		\end{itemize}
%	\end{itemize}
%	
%	\begin{figure}
%		\centering
%		\includegraphics[width=70mm]{ampi14}
%	\end{figure}
%\end{frame}
%
%
%\begin{frame}[t]
%	\frametitle{Redes Neurais Artificiais}
%	\begin{itemize}
%		\item RNAs são modelos de computação com propriedades particulares:
%		
%		\begin{itemize}
%			\item Aprender
%			
%			\item \textbf{Adaptar}
%			
%			\item Generalizar
%			
%			\item Eventualmente organizar
%		\end{itemize}
%	\end{itemize}
%	
%	\begin{figure}
%		\centering
%		\includegraphics[width=70mm]{ampi15}
%	\end{figure}
%\end{frame}
%
%
%\begin{frame}[t]
%	\frametitle{Redes Neurais Artificiais}
%	\begin{itemize}
%		\item RNAs são modelos de computação com propriedades particulares:
%		
%		\begin{itemize}
%			\item Aprender
%			
%			\item Adaptar
%			
%			\item \textbf{Generalizar}
%			
%			\item Eventualmente organizar
%		\end{itemize}
%	\end{itemize}
%	
%	\begin{figure}
%		\centering
%		\includegraphics[width=66mm]{ampi16}
%	\end{figure}
%\end{frame}
%
%
%\begin{frame}[t]
%	\frametitle{Redes Neurais Artificiais}
%	\begin{itemize}
%		\item RNAs são modelos de computação com propriedades particulares:
%		
%		\begin{itemize}
%			\item Aprender
%			
%			\item Adaptar
%			
%			\item Generalizar
%			
%			\item \textbf{Eventualmente organizar}
%		\end{itemize}
%	\end{itemize}
%	
%	\begin{figure}
%		\centering
%		\includegraphics[width=60mm]{ampi17}
%	\end{figure}
%\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Estrutura genérica de uma RNA
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=70mm]{ampi18}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Diferentes arranjos, topologia
		
		\begin{itemize}
			\item \textit{Feedforward}, recorrente, em mapa
			
			%Feedforward: Não possuem ciclos nem memória; cada entrada é processada de forma independente.
			
			% Redes recorrentes: possuem conexões cíclicas: a saída de um neurônio pode ser realimentada como entrada em etapas seguintes. Isso confere memória de curto prazo, permitindo modelar dependências temporais e sequenciais
			
			%em mapa: São redes não supervisionadas que realizam redução de dimensionalidade e clusterização
		\end{itemize}
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=40mm]{ampi19}
		\includegraphics[width=40mm]{ampi21}
		\includegraphics[width=20mm]{ampi20}
	\end{figure}
	
	\begin{itemize}
		\item[] \text{ ~ ~ ~ } \textit{Feedforward} \text{ ~ ~ ~ ~ ~ ~ } Recorrente \text{~ ~ ~ ~ ~} Em mapa
	\end{itemize}
	
	%feedforward:  são um tipo de arquitetura de rede neural que processa dados em uma única direção, da camada de entrada para a camada de saída
	
	% recorrente: são um tipo de rede neural artificial que processa dados sequenciais, como palavras, frases ou dados de séries temporais. Suas saídas são realimentadas como sinais de entrada para outros neurônios, sendo assim empregadas para o processamento de sistemas variantes no tempo (figura 3). São empregadas em previsões de séries temporais, otimização, identificação de sistemas e controle de processos.
	
	%Enquanto as redes feedforward têm diferentes pesos em cada nó, as redes neurais recorrentes compartilham o mesmo parâmetro de peso dentro de cada camada da rede.
	
	
	%O Mapa Auto-Organizável, também conhecido como Mapa de Kohonen é uma rede neural artificial não-supervisionada de aprendizado competitivo formada por uma grade de neurônios artificiais.
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Exemplo
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=100mm]{ampi22}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Ciclo do projeto de uma RNA
		
		\begin{enumerate}
			\item Obtenção de dados\\~\\
			
			\item Escolha de características\\~\\
			
			\item Treinamento (aprendizagem)\\~\\
			
			\item Avaliação\\~\\
			
			\item Complexidade computacional
		\end{enumerate}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Principais aspectos das RNA
		
		\begin{itemize}
			\item Arquitetura
			
			\begin{itemize}
				\item Neurônios artificiais (unidades de processamento)\\~\\ %Unidades de processamento inspiradas nos neurônios biológicos. ada neurônio calcula uma função de ativação sobre a combinação ponderada das entradas. Exemplos comuns de funções de ativação: ReLU, sigmóide, tangente hiperbólica.
				
				\item Conexões\\~\\ %As saídas dos neurônios são conectadas como entradas para outros neurônios. As conexões possuem pesos sinápticos ajustáveis, que determinam a influência entre os neurônios. A aprendizagem consiste justamente na modificação adaptativa desses pesos.
				
				\item Topologia\\~\\ %Refere-se à organização e estrutura das camadas e conexões: Redes Feedforward: conexões unidirecionais sem ciclos. Redes Recorrentes (RNNs): conexões com ciclos, permitindo memória. Convolucionais (CNNs): conexões locais e compartilhamento de pesos, comuns em processamento de imagens. Auto-organizáveis (SOMs): topologias fixas para aprendizado não supervisionado.
			\end{itemize}
		
			\item Aprendizado
			
			\begin{itemize}
				\item Algoritmos\\~\\ %Processos matemáticos para ajustar os pesos da rede visando minimizar uma função de custo. Stochastic Gradient Descent (SGD), como Adam, RMSProp, Adagrad. Outros métodos: algoritmos evolutivos, swarm, momentum
				
				\item Paradigmas\\~\\ %supervisionado, não-supervisionado, reforço
				
				
%				Adam (Adaptive Moment Estimation) é um algoritmo de otimização usado para ajustar os pesos das redes neurais durante o treinamento. Ele combina as vantagens de dois outros métodos populares:
%				
%				Momentum (que acelera o gradiente na direção das atualizações)
%				
%				RMSProp (que adapta a taxa de aprendizado para cada parâmetro)
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Unidades de processamento
		
		\begin{itemize}
			\item Recebimento entradas de conjuntos de unidades\\~\\
			
			\item Aplicação de uma função sobre as entradas\\~\\
			
			\item Envio do resultado da função para um outro conjunto de unidades\\~\\ 
			
			\item Exemplos:
			
			\begin{equation*}
				u = \sum\limits_{i = 1}^{m} x_i w_i
			\end{equation*}
		
			\begin{figure}
				\centering
				\includegraphics[width=34mm]{neuro2}
			\end{figure}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Conexões
		
		\begin{itemize}
			\item Definem a interligação entre os neurônios\\~\\
			
			\item Codificação do conhecimento da rede\\~\\
			
			\item Conexão inibitória: $(w_{ik} (t) < 0)$\\~\\
			
			\item Conexão excitatória: $(w_{ik} (t) > 0)$\\~\\
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Topologia
		
		\begin{itemize}
			\item Número de camadas\\~\\
			
			\item Cobertura das conexões
			
			\begin{figure}
				\centering
				\includegraphics[width=40mm]{neuro3}
			\end{figure}
			
			\item[]
			
			\item Arranjo das conexões
			
			\begin{figure}
				\centering
				\includegraphics[width=40mm]{neuro4}
			\end{figure}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{itemize}
		\item Aprendizado %Refere-se a como os parâmetros (pesos e vieses) da rede são ajustados durante o treinamento.
		
		\begin{itemize}
			\item Define como os parâmetros de rede são ajustados\\~\\ 
			
			\item Principais formas de ajuste
			
			\begin{itemize}
				\item Correção de erro\\~\\ %Base do backpropagation: ajusta os pesos para reduzir a diferença (erro) entre a saída desejada e a saída da rede
				
				\item Hebbiano\\~\\ %Inspirado no cérebro: ?neurônios que disparam juntos, conectam-se mais fortemente?. Se duas unidades são ativadas simultaneamente, a conexão entre elas é reforçada. Mais usado em redes não supervisionadas e modelos associativos.
				
				\item Competitivo\\~\\ %Neurônios competem entre si; apenas o mais ativado ?vence? e ajusta seus pesos. Leva à formação de especializações (clusters).
				
				\item Termodinâmico (Boltzmann)\\~\\ %Baseado em princípios da física estatística (energia e temperatura).
			\end{itemize}
		\end{itemize}
	
		\item Paradigma de aprendizado
		
		\begin{itemize}
			\item Define as informações externas que são passadas para a rede durante o processo de aprendizado\\~\\
			
			\item Exemplos de abordagens: supervisionado, não-supervisionado, semi-supervisionado, reforço
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}%[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{figure}
		\centering
		\includegraphics[width=100mm]{ampi23}
	\end{figure}
\end{frame}


\begin{frame}%[t]
	\frametitle{Redes Neurais Artificiais}
	\begin{figure}
		\centering
		\includegraphics[width=100mm]{ampi24}
	\end{figure}
\end{frame}


\begin{frame}
	\frametitle{Sumário}
	\begin{block}{}
		\begin{center}\bf Perceptron\end{center}
	\end{block}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\begin{itemize}
		\item Rede neural elementar baseada em uma unidade chamada Perceptron criada por Rosenblatt em 1958
		
		\begin{itemize}
			\item O Perceptron permite uma compreensão clara de como funciona uma rede neural em termos matemáticos\\~\\
		\end{itemize}
		
		\item Um Perceptron é um modelo matemático que recebe várias entradas, $x1, x2, ...$ e produz uma única saída binária
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=50mm]{ampi25}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\begin{figure}
		\centering
		\includegraphics[width=50mm]{ampi26}
	\end{figure}
	
	\begin{itemize}
		\item Nesse exemplo, o Perceptron possui três entradas: $x1, x2, x3$\\~\\
		
		\item Rosenblatt propôs uma regra simples para calcular a saída: introdução de  pesos, $w1, w2, ...$, números reais expressando a importância das respectivas entradas para a saída\\~\\ 
		
		\item A saída do neurônio, 1 ou -1, é determinada pela soma ponderada, $\sum\limits_{j}w_j x_j$, menor ou maior do que algum valor limiar (\textit{threshold})
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\begin{itemize}
		\item Modelo desenvolvido por Rosenblatt em 1958
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{ampi27}
	\end{figure}
	
	\begin{itemize}\scriptsize
		\item Onde:
		
		\begin{itemize}\scriptsize
			\item Cada elemento $w_i$ é uma constante de valor real, ou peso, que determina a contribuição da entrada $x_i$ na saída do perceptron\\~\\
			
			\item A aprendizagem do perceptron envolve a escolha dos pesos de $w_0$ a $w_n$\\~\\
			
			\item A camada de entrada deve possuir uma unidade especial conhecida como bias, que é uma entrada de valor constante associada a um peso $w_i$ em cada neurônio $i$
			
			%			magine o seguinte: Todo dia voce vai à padaria, compra algumas
			%			coisas pra comer e quando chega em casa voce toma café.
			%			? Porém as vezes compra pão, as vezes compra bolo ou outras
			%			coisa, mas sempre compra café .
			%			? O bias é isso, o café, é o valor constante que independente do
			%			outros valores esse valor sempre vai ter lá.
			%			? Ou seja, se teu café custa 3,50 sempre, as vezes as outras coisas
			%			que voce comprar podem custar 10 reais, 7 reais, esses são os
			%			valores da entrada, mas voce sempre vai ter o teu bias custando
			%			3,50 que é o seu café.
		\end{itemize}
	
	%viés: Aumenta a capacidade do modelo ao permitir que a função de ativação seja deslocada. Com o viés, o modelo pode aprender a separar classes que não podem ser separadas se o limite for forçado a passar pela origem.
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\begin{itemize}
		\item Podemos ``ver'' o perceptron como uma superfície de separação em um espaço de instâncias
		
		\begin{itemize}
			\item O perceptron fornece ``1'' para instâncias dispostas em um lado do hiperplano e ``-1'' para instâncias dispostas no outro lado\\~\\
			
			\item Um único perceptron consegue separar somente conjuntos de exemplo linearmente separáveis
		\end{itemize}
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=50mm]{ampi28}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Como aprender os pesos para um perceptron?
		
		\begin{itemize}
			\item Problema: determinar um vetor de pesos que faça o perceptron produzir a saída correta (-1 ou +1) para cada um dos exemplos de treinamento\\~\\
			
			\item Solução: Começar com um vetor de pesos aleatórios e aplicar iterativamente a regra perceptron para cada exemplo de treinamento, modificando os pesos cada vez que ele classificar um exemplo erroneamente
			
			\begin{itemize}
				\item Este processo é repetido várias vezes até que o perceptron classifique todos os exemplos de treinamento corretamente ou a taxa de erro ser aceitável ou até atingir o número de ciclos completos de treinamento (\textit{epochs})
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Os pesos do perceptron são modificados a cada passo de acordo com a regra de treinamento do perceptron, que modifica o peso $w_i$ associado a entrada $x_i$ de acordo com a regra:
		
		\begin{equation*}
			w_i = w_i + \Delta w_i
		\end{equation*}
		
		\begin{itemize}
			\item Onde
			
			\begin{equation*}
				\Delta w_i = \eta (t - o) x_i
			\end{equation*}
			
			\begin{itemize}
				\item $t$ é o valor alvo para o exemplo de treinamento (alvo = classe)\\~\\
				
				\item $o$ é a saída gerada pelo perceptron ( o que ele classificou)\\~\\
				
				\item $\eta$ é uma constante pequena (0.1) chamada de taxa de aprendizagem %Valores altos de TA: Atualizações grandes demais ? pode não convergir, pular o mínimo da função de erro. Baixa: Atualizações pequenas demais ? treinamento lento, pode ficar preso em mínimos locais ou demorar demais para convergir
				
				%convergência no treinamento significa o momento em que o processo iterativo de ajuste dos pesos atinge uma estabilidade
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Se o exemplo de treinamento é classificado corretamente:
		
		\begin{itemize}
			\item[]  $(t - 0) = 0$ \text{~ ~ ~ ~ } $\Delta w_i = 0$\\~\\
		\end{itemize}
		
		\item Se o exemplo de treinamento é classificado incorretamente, o valor de $\Delta w_i$ é alterado:
		
		\begin{itemize}
			\item Se $x_i = 0,8$, $\eta = 0,1$, $t = 1$, $o = -1$\\~\\
			
			\item A atualização do peso é dado por: $\Delta w_i = \eta(t - o) x_i = 0,1 (1 - (-1)) 0,8 = 0.16$\\~\\
		\end{itemize}
		
		\item Pode-se provar que este procedimento de aprendizagem converge dentro de um número finito de passos quando: %Convergir no contexto de aprendizado de máquina e redes neurais significa que, durante o treinamento, o modelo vai se ajustando progressivamente até que suas alterações nos parâmetros (pesos e vieses) fiquem pequenas e estáveis, e o erro ou função de custo atinja um valor mínimo ou próximo disso
		
		\begin{itemize}
			\item As classes dos dados de treinamento são linearmente separáveis\\~\\
			
			\item $\eta$ é suficientemente pequeno
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}%[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{figure}
		\centering
		\includegraphics[width=60mm]{ampi29} % vetor x e classe rotulada d; Calcular saída: classe prevista y
		\includegraphics[width=60mm]{ampi30} %Encontrar classe(y) que é um padrão desconhecido
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Função de ativação
		
		\begin{itemize}
			\item A função de ativação basicamente decidem se um neurônio deve ser ativado ou não
		\end{itemize}
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=70mm]{ampi31}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Função de ativação
		
		\begin{itemize}
			\item Existem vários tipos de função de ativação, cada qual usado em diferentes situações\\~\\
			
			\item No caso do Perceptron, é uma função de limiar (também chamado degrau) 
			
			\begin{itemize}
				\item Nesse caso depois de calculado a somatória de $x_i w_i$, é verificado o limiar para encontrar qual classe pertence
			\end{itemize}
		\end{itemize}
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=34mm]{ampi32}
	\end{figure}
\end{frame}



\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Modificando fronteiras
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{neuro5}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Modificando fronteiras
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{neuro6}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Modificando fronteiras
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{neuro7}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Modificando fronteiras
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{neuro8}
	\end{figure}
\end{frame}


%\begin{frame}[t]
%	\frametitle{Perceptron}
%	\framesubtitle{Regras de treinamento de perceptron}
%	\begin{itemize}
%		\item Objetivo do perceptron com função de ativação
%	\end{itemize}
%	
%	\begin{figure}
%		\centering
%		\includegraphics[width=90mm]{ampi33}
%	\end{figure}
%\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Exemplo
		
		\begin{itemize}
			\item Dada uma rede perceptron com três entradas, pesos $w_1 = 0,4$, $w_2 = -0,6$ e $w_3 = 0,6$, e limiar (viés) $\theta = 0,5$\\~\\
			
			\item Ensinar a rede com os exemplos (001, -1) e (110, +1), considerando uma taxa de aprendizado $\eta = 0,4$\\~\\
			
			
			\item Classificar os exemplos: 111, 000, 100 e 011
		\end{itemize}
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=60mm]{neuro9}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\framesubtitle{Regras de treinamento de perceptron}
	\begin{itemize}
		\item Exemplo: treinamento para o exemplo 001, cuja classe é $y = -1$
		
		\begin{itemize}
			\item Passo 1: determinar a saída da rede
			
			\begin{itemize}
				\item $u = -1(0,5) + 0(0,4) + 0(-0,6) + 1(0,6) = 0,1$\\~\\
				
				\item $f(u) = +1$ ($0,1 \geq 0$)\\~\\
				
			\end{itemize}
		
			\item Passo 2: atualizar os pesos ($y \neq f(u)$): $w_i = w_i + x_i \eta(t - o)$
			
			\begin{itemize}
				\item $w_0 = 0,5 + 0,4(-1)(-1 - (+1)) = 1,3$\\~\\
				
				\item $w_1 = 0,4 + 0,4(0)(-1 - (+1)) = 0,4$\\~\\
				
				\item $w_2 = -0,6 + 0,4(0)(-1 - (+1)) = -0,6$\\~\\
				
				\item $w_3 = 0,6 + 0,4(1)(-1 - (+1)) = -0,2$
			\end{itemize}
		\end{itemize}
	\end{itemize}
	
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\begin{itemize}
		\item Exemplo: teste para classificar os exemplos 111, 000, 100 e 011
		
		\begin{itemize}
			\item Pesos aprendidos: 0,5, 1,2, 0,2 e -0,2\\~\\
			
			\item Exemplo 111
			
			\begin{itemize}
				\item $u = -1(0,5) + 1(1,2) + 1(0,2) + 1(-0,2) = 0,7$\\~\\
				
				\item $f(u) = +1$ ($0,7 \geq 0$)\\~\\
			\end{itemize}
		
			\item Exemplo 000
			
			\begin{itemize}
				\item $u = -1(0,5) + 0(1,2) + 0(0,2) + 0(-0,2) = -0,6$\\~\\
				
				\item $f(u) = -1$ ($-0,6 < 0$)\\~\\
			\end{itemize}
		\end{itemize}
	\end{itemize}
	
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron}
	\begin{itemize}
		\item O perceptron falha em convergir se as classes forem linearmente não-separáveis
		\begin{itemize}
			\item Exemplo: XOR
		\end{itemize}
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{neuro10}
	\end{figure}
\end{frame}



\begin{frame}
	\frametitle{Sumário}
	\begin{block}{}
		\begin{center}\bf Perceptron Multicamadas\end{center}
	\end{block}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\begin{itemize}
		\item É um perceptron que se une a perceptrons adicionais, empilhados em várias camadas, para resolver problemas complexos
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{neuro11}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\begin{itemize}
		\item Uma rede neural com ao menos uma camada intermediária e um modelo denominada perceptron de múltiplas camadas (MLP -- \textit{multilayer perceptron})\\~\\
		
		\item Cada entrada envia vários sinais
		
		\begin{itemize}
			\item Um sinal indo para cada perceptron na próxima camada\\~\\
			
			\item Para cada sinal, o perceptron usa pesos diferentes
		\end{itemize}
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=65mm]{ampi35}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\begin{itemize}
		\item Vimos que a estrutura de um perceptron clássico inclui uma função de ativação com limiar que, tendo em vista a natureza do problema de classificação, é abrupta\\~\\
		
%		\item No entanto, uma não-linearidade desse tipo pode gerar dificuldades\\~\\
		
		\item MLPs utilizam funções de ativação sigmoidais, que possuem um perfil de ``S'', ou seja, de um degrau suave
		
		\begin{figure}
			\centering
			\includegraphics[width=80mm]{ampi36}
		\end{figure}
	
	\end{itemize}
	
	
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\begin{itemize}
		\item No início do treinamento do classificador, a rede comete erros o tempo todo!\\~\\
		
		\item Gradualmente, o desempenho da rede melhora no decorrer do processo de treinamento\\~\\
		
		\item Após a ocorrência de erros propagados entre as camadas durante o treinamento, a rede volta atrás, a partir da última camada até a primeira, para a correção de erros
		
		\begin{itemize}
			\item Esse processo iterativo de passar uma amostra pela rede e voltar atrás para se corrigir é conhecido como aprendizado profundo, e é o que torna as redes com inteligência mais próxima à humana\\~\\
			
			\item O treinamento de redes MLPs é feito utilizando o algoritmo \textit{backpropagation}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\framesubtitle{Algoritmo \textit{backpropagation}}
	\begin{itemize}
		\item Treinamento em duas fases %, sendo cada uma em um
		
		\begin{itemize}
			\item \textit{Forward}\\~\\
			
			\item \textit{Backward}\\~\\
		\end{itemize} 
	\end{itemize}

	\begin{figure}
		\centering
		\includegraphics[width=54mm]{neuro12}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\framesubtitle{Algoritmo \textit{backpropagation}}
	\begin{itemize}
		\item Treinamento
		
		\begin{itemize}
			\item Supervisionado\\~\\
			
			\item Uso de gradiente descendente\\~\\ %É um algoritmo de otimização usado para ajustar os pesos da rede neural de forma a minimizar a função de erro (ou custo). Calcular a direção em que o erro cresce mais rapidamente (gradiente). Atualizar os pesos na direção oposta (descida) para reduzir o erro.
			
			
			\item Ajuste dos pesos: $\Delta w_{ij} = \eta x_{i} \delta_{j}$
			
			%\delta é o gradiente
			
			\begin{itemize}
				\item $\delta_{j} = f'(net) erro_{j}$, se $j$ for camada de saída
				
				\item $\delta_{j} = f'(net) \sum w_{jk} \delta_{k}$, se $j$ for camada intermediária
				
				\item $erro_{j} = \frac{1}{2} \sum\limits_{q = 1}^{c}(y_{q} - f(net_q))^2$
				
				\item $net = \sum\limits_{i = 0}^{m}x_{i}w_{i}$\\~\\
			\end{itemize}
		
			\item Se $f(net)$ for uma função sigmoidal, $f'(net) = f(net)(1 - f(net))$\\~\\
			
			\item Convergência não é garantida no treinamento do modelo! %A função que o treinamento tenta minimizar (ex: erro quadrático) em redes MLP é não convexa. Gradientes desaparecendo ou explodindo: Em redes profundas, durante o backpropagation, o gradiente pode se tornar muito pequeno (vanishing gradient) ou muito grande (exploding gradient), dificultando atualizações efetivas dos pesos. Pesos mal inicializados podem levar o treinamento a ficar preso em mínimos ruins ou atrasar muito a convergência.
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\framesubtitle{Algoritmo \textit{backpropagation}}
	\begin{itemize}
		\item Função de ativação
		
		\begin{itemize}
			\item Não linear\\~\\
			
			\item Diferenciável, contínua e não decrescente (geralmente)\\~\\ %O backpropagation depende da derivada da função de ativação para calcular os gradientes e ajustar os pesos. Sem uma derivada, o algoritmo não consegue computar as atualizações corretamente. Contínua: Evita mudanças bruscas na saída em função de pequenas variações na entrada.
			
			\item Sigmoidal
			
			\begin{itemize}
				\item Logística: $f(x) = \frac{1}{1 + e^{-net}}$\\~\\ %saida: intervalo (0, 1). Usada normalmente na saída para classificação binária (ex.: probabilidade)
				
				\item Tangente hiperbólica: $f(x) = \frac{1 - e^{-net}}{1 + e^{-net}}$% Saída: intervalo (-1, 1). Centrada em zero. Usada Em camadas ocultas para manter saída centrada em zero e ajudar na convergência
			\end{itemize}
		\end{itemize}
	\end{itemize}

	\begin{figure}
		\centering
		\includegraphics[width=40mm]{neuro13}
	\end{figure}
\end{frame}


\begin{frame}%[t]
	\frametitle{Perceptron Multicamadas}
	\framesubtitle{Algoritmo \textit{backpropagation}}
	\begin{itemize}
		\item Treinamento
	\end{itemize}
	
	\begin{figure}
		\centering
		\includegraphics[width=80mm]{neuro14}
	\end{figure}
\end{frame}


\begin{frame}[t]
	\frametitle{Perceptron Multicamadas}
	\framesubtitle{Algoritmo \textit{backpropagation}}
	\begin{itemize}
		\item \textit{Foward} (propagação para frente)
		
		\begin{itemize}
			\item Alimentação da camada de entrada\\~\\
			
			\item Ativação de cada neurônio utilizando ativações e pesos da camada anterior (se houver) e uma função de ativação
			
			\begin{itemize}
				\item Essa ativação é feita em camada por camada até a de saída\\~\\
			\end{itemize}
		
			
			\item Cálculo do erro gerado na última camada (função de perda)\\~\\ %A saída da rede é comparada com a saída desejada (rótulo verdadeiro) para a amostra de entrada.
		\end{itemize}
		
		\item \textit{Backward} (propagação para trás)
		
		\begin{itemize}
			\item Propagação do erro camada por camada\\~\\
			
			\item Cálculo da contribuição (gradiente) de cada neurônio para o erro total\\~\\ %Isso é feito usando a regra da cadeia do cálculo diferencial. A regra da cadeia permite calcular o gradiente (a taxa de variação) da função de custo em relação a cada peso na rede. Especificamente, o algoritmo calcula as derivadas parciais do erro em relação aos pesos das conexões e aos biases (termos de viés) de cada neurônio. Essas derivadas indicam a sensibilidade do erro a cada parâmetro da rede. Em outras palavras, elas nos dizem o quanto o erro mudaria se ajustássemos ligeiramente cada peso ou bias. O gradiente nos diz quanto e em qual direção cada peso deve ser ajustado para reduzir o erro mais rapidamente.
			
			\item Atualização dos pesos %Uma vez que os gradientes do erro em relação a todos os pesos e biases foram calculados, esses parâmetros são ajustados para minimizar o erro. O algoritmo de otimização mais comum usado para essa atualização é o Gradiente Descendente (Gradient Descent). A ideia é mover os pesos e biases na direção oposta ao gradiente do erro. Pense nisso como descer uma montanha até o vale mais baixo (o mínimo do erro). A magnitude do ajuste é controlada pela taxa de aprendizado (learning rate), um hiperparâmetro que determina o tamanho do passo dado na direção do gradiente. Uma taxa de aprendizado muito alta pode fazer com que o algoritmo "pule" o mínimo, enquanto uma taxa muito baixa pode tornar o treinamento muito lento.
		\end{itemize}
	\end{itemize}
\end{frame}


%\begin{frame}[t]
%	\frametitle{Perceptron Multicamadas}
%	\framesubtitle{Algoritmo \textit{backpropagation}}
%	\begin{itemize}
%		\item 
%	\end{itemize}
%\end{frame}
%
%
%\begin{frame}[t]
%	\frametitle{Perceptron Multicamadas}
%	\framesubtitle{Algoritmo \textit{backpropagation}}
%	\begin{itemize}
%		\item 
%	\end{itemize}
%\end{frame}
%
%
%\begin{frame}[t]
%	\frametitle{Perceptron Multicamadas}
%	\framesubtitle{Algoritmo \textit{backpropagation}}
%	\begin{itemize}
%		\item 
%	\end{itemize}
%\end{frame}
%
%
%\begin{frame}[t]
%	\frametitle{Perceptron Multicamadas}
%	\framesubtitle{Algoritmo \textit{backpropagation}}
%	\begin{itemize}
%		\item 
%	\end{itemize}
%\end{frame}


%\begin{frame}[t]
%	\frametitle{Perceptron Multicamadas}
%	\begin{itemize}
%		\item Exemplo tangente
%	\end{itemize}
%	
%	\begin{figure}
%		\centering
%		\includegraphics[width=100mm]{ampi37}
%	\end{figure}
%\end{frame}


\begin{frame}%[t]
	\frametitle{Perceptron Multicamadas}
	\begin{figure}
		\centering
		\includegraphics[width=110mm]{ampi41}
	\end{figure}
	
	%	Exemplos de implementação
	%	https://medium.com/ensina-ai/rede-neural-perceptron-multicamadas-f9de847
	%	1f1a9
	%	https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLP
	%	Classifier.html
	%	https://towardsdatascience.com/deep-neural-multilayer-perceptron-mlp-with-s
	%	cikit-learn-2698e77155e
\end{frame}




\begin{frame}[allowframebreaks]
	\frametitle<presentation>{Referências}
	
	\begin{thebibliography}{10}
		\bibitem{Bishop}
		BISHOP C. \newblock Neural Networks for Pattern Recognition. \newblock Oxford University Press, 1995.
		
		\bibitem{Carvalho}
		CARVALHO, A. P. L. F.
		\newblock Árvores de Características. Aprendizado de Máquina.
		\newblock {\em Slides}. Ciência de Computação e Matemática Computacional. ICMC/USP, 2015.
		
		\bibitem{duda}
		DUDA R., Hart P., STORK D. \newblock Pattern Classification. \newblock Willey Interscience, 2002.
		
		\bibitem{Haykin}
		HAYKIN S. \newblock Neural Networks: A Comprehensive Foundation. \newblock Prentice Hall, 1988.
		
		\bibitem{Mitchell}
		MITCHELL T. \newblock Machine Learning. \newblock WCB McGraw-Hill, 1997.
		
		\bibitem{raschka}
		RASCHKA, S.; MIRJALILI, V. \newblock \em{Python Machine Learning.} \newblock Packt, 2017.
	\end{thebibliography}
\end{frame}


\end{document}
